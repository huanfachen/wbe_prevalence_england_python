{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8df7757",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59bbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_labels = {\n",
    "    'sars_cov2_gc_l_mean': 'SARS-CoV-2 concentration',\n",
    "    'sample_ph_pre_ansis':'sample pH',\n",
    "    'ammonia_mg_l':'ammonia concentration',\n",
    "    'control_gc_l_mean':'control volume',\n",
    "    'ophosph_mg_l':'phosphate concentration',\n",
    "    'suspended_solids_mg_l':'suspended solids',\n",
    "    'sars_below_loq':'below LOQ',\n",
    "    'sars_below_lod':'below LOD',\n",
    "    'compo_frac':'composites fraction',\n",
    "    'reception_delay':'reception delay',\n",
    "    'catch_cis_population':'covered population',\n",
    "    'catch_in_cis_prop':'subregion population fraction',\n",
    "    \"catchment_population_ons_mid_2019\": \"catchment population\",\n",
    "    \"catchment_area\": 'catchment area'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51c4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/data/loading_cis.py:19: UserWarning: Data not yet ingested properly, please change the link to ingested dataset as soon as possible.\n",
      "  warnings.warn('Data not yet ingested properly, please change the link to ingested dataset as soon as possible.')\n",
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/data/loading_cis.py:32: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_cis = df_cis.drop(df_cis.columns[0], 1)\n",
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/data/loading_cis.py:33: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_cis = df_cis.drop(['CIS.name', 'RGN19CD'],1).merge(df_cis[['cis_num', 'CIS.name', 'RGN19CD']].drop_duplicates().dropna())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest flow normalisation file: 20220314_EXPORT_SARS_COV2_FLOW_NORMALISATION.csv\n",
      "Loading latest anomaly file: 20211018_EXPORT_SARS_COV2_CONCENTRATION_ANOMALY.csv\n",
      "Missing values (-2 convention) have been replaced by nan\n",
      "Samples to be rerun (-1 convention) have been replaced by nan\n",
      "141 samples with wrong or missing dates (date_sample_collected) have been removed.\n",
      "Selected 311 sites after filter on SEWAGE TREATMENT PLANT (site_type)\n",
      "Selected 306 sites after filter on UK* codes\n",
      "Selected 45 sites with first sample before 2021-01-01\n",
      "LOD ([-4]) and LOQ ([-3, 0]) codes for ['flow_normalised_sars_cov2_gc_l_mean', 'sars_cov2_gc_l_mean'] have been replaced by LOD/2 and LOQ/2 respectively, using default values of LOD=133 and LOQ=1333 where missing in data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/preprocessing.py:476: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  reception_time = pd.to_datetime(df_ww.time_sample_received.astype(str).str.pad(4, fillchar='0'), format='%H%M')- pd.datetime(1900,1,1)\n",
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/preprocessing.py:477: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  collection_time = pd.to_datetime(df_ww.time_sample_collected.astype(str).str.pad(4, fillchar='0'), format='%H%M')- pd.datetime(1900,1,1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import wastewater as ww\n",
    "from wastewater.ml_utils import Dataset, RandomIntercepts, RandomEffects\n",
    "\n",
    "# CIS Data\n",
    "df_cis = ww.load_cis(daily=False).rename(columns={'CIS.name':\"CIS20CD\"})\n",
    "df_cis_interpolated = ww.load_cis(daily=True, kind='linear').rename(columns={'CIS.name':\"CIS20CD\"})\n",
    "\n",
    "# Preprocess WW data\n",
    "df_ww = ww.read_ww()\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_1_dec21.csv')      # example saving to data_dir\n",
    "df_ww = ww.drop_wrong_dates(df_ww)\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_2_dec21.csv')      # example saving to data_dir\n",
    "df_ww = ww.select_specific_sites(df_ww)\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_3_dec21.csv') # example saving to data_dir\n",
    "df_ww = ww.select_sites_sampled_before(df_ww, '2021-01-01')\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_4_dec21.csv') # example saving to data_dir\n",
    "df_ww =  df_ww.merge(ww.read_sites()[['ww_site_code', 'catchment_population_ons_mid_2019', 'ww_catchment_code']])\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_5_dec21.csv')\n",
    "df_ww = df_ww.drop_duplicates(subset=['date_sample_collected', 'ww_site_code'])\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_6_dec21.csv') \n",
    "# it would be preferable here to change the calculation of SARS-CoV-2 gc/l for those without replicate data\n",
    "df_ww = ww.replace_loq_lod(df_ww, 133, 1333)\n",
    "df_ww.loc[df_ww.ophosph_mg_l==-3, 'ophosph_mg_l'] = np.nan\n",
    "df_ww = ww.add_new_ww_features(df_ww, reception_delay=True)\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_7_dec21.csv') # example saving to data_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38982947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12745.000000\n",
      "mean        66.463712\n",
      "std        214.241247\n",
      "min         -4.000000\n",
      "25%         -3.000000\n",
      "50%          9.036000\n",
      "75%         41.236988\n",
      "max       5059.119141\n",
      "Name: raw_ansis_sars_repc_1, dtype: float64\n",
      "14351\n",
      "first replicate =  1606  and  11.19 %\n",
      "second replicate =  1606  and  11.19 %\n"
     ]
    }
   ],
   "source": [
    "# check whether replicate data pre-freb 2021 are loaded in\n",
    "# below doesn't 'quite' get to it, but ~10% samples are with NAs, so that's ok\n",
    "df_ww.head()\n",
    "# list(df_ww.columns)\n",
    "# 'raw_ansis_sars_repc_1',\n",
    "# 'raw_ansis_sars_repc_2',\n",
    "print(df_ww['raw_ansis_sars_repc_1'].describe())\n",
    "nas1 = df_ww['raw_ansis_sars_repc_1'].isna().sum()\n",
    "nas2 = df_ww['raw_ansis_sars_repc_2'].isna().sum()\n",
    "rows = len(df_ww)\n",
    "print(rows)\n",
    "print('first replicate = ',nas1,' and ', round(100*(nas1/rows),2),'%')\n",
    "print('second replicate = ',nas2,' and ', round(100*(nas2/rows),2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "564b1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_coll  rep1na\n",
      "2020       False     3376\n",
      "           True       745\n",
      "2021       False     7755\n",
      "           True       803\n",
      "2022       False     1614\n",
      "           True        58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add in year of collection from date\n",
    "df_ww['year_coll'] = pd.DatetimeIndex(df_ww['date_sample_collected']).year\n",
    "df_ww['rep1na'] = df_ww['raw_ansis_sars_repc_1'].isna()\n",
    "df_ww['rep2na'] = df_ww['raw_ansis_sars_repc_2'].isna()\n",
    "# create a table of observations\n",
    "#print(df_ww['year_coll'].value_counts())\n",
    "#print(df_ww['rep1na'].value_counts())\n",
    "# to have NAs by year of collection I think I need to..\n",
    "# - create a variable 0/1 of whether replicate is NA or not\n",
    "# - create a table = df_ww.groupby('year_coll','is_na').size()\n",
    "table = df_ww.groupby(['year_coll','rep1na']).size()\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e161e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.274300e+04\n",
      "mean    -3.673614e-01\n",
      "std      1.518420e+00\n",
      "min     -2.813997e+01\n",
      "25%     -9.536743e-07\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      2.845380e+01\n",
      "Name: repc_mean_check, dtype: float64\n",
      "This number of values are incorrectly calculated 9237 and percentage 64.36485262351056\n"
     ]
    }
   ],
   "source": [
    "# check how the mean value s calculated, and update if it isn't correct.\n",
    "# raw_ansis_sars_repc_mean\n",
    "# df_ww['raw_ansis_sars_repc_mean_v2'] = (df_ww['raw_ansis_sars_repc_1'] + df_ww['raw_ansis_sars_repc_2'])/2\n",
    "# need to select obs where only 1 rep is available, and update\n",
    " \n",
    "def my_repfun (var1,var2,var3):\n",
    "    df_ww[var3] = np.where((df_ww[var1]<0), df_ww[var2], (df_ww[var1]+df_ww[var2])/2) # if values of var1 <0, use var2 only \n",
    "    df_ww[var3] = np.where((df_ww[var2]<0), df_ww[var1], df_ww[var3]) # if values of var2 <0, use var3 only, now that we have made it \n",
    "    df_ww[var3] = np.where((df_ww[var1].isna()), df_ww[var2], df_ww[var3]) # if values of var2 <0, use var3 only, now that we have made it \n",
    "    df_ww[var3] = np.where((df_ww[var2].isna()), df_ww[var1], df_ww[var3]) # if values of var2 <0, use var3 only, now that we have made it \n",
    "    return df_ww\n",
    "\n",
    "df_ww = my_repfun('raw_ansis_sars_repc_1','raw_ansis_sars_repc_2','raw_ansis_sars_repc_mean_v2')\n",
    "df_ww['repc_mean_check'] = df_ww['raw_ansis_sars_repc_mean'] - df_ww['raw_ansis_sars_repc_mean_v2']\n",
    "print(df_ww['repc_mean_check'].describe())\n",
    "tmp = sum(df_ww['repc_mean_check']!=0)\n",
    "print('This number of values are incorrectly calculated',tmp,'and percentage',100*(tmp/rows))\n",
    "\n",
    "# well ... this hasn't been corrected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d43743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFpCAYAAADTDCGuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoo0lEQVR4nO3df4zc9X3n8dd7hwUGLtkNBSKx4LPLWqZJnGBlBEbWSW6urp0Qg+W04YeRrlVkK5GolCZyYx/WEVSo3dtLSlK4y5liublY/AhxR2ztdi+6hBJR4Lx0gY0Je3UIBQ9ScQLrtrAJy/p9f+yOmR3Pj+93vt/5fr8z83xIUTTfmfnOJ99Y+MXn8/68P+buAgAASEJf2gMAAAC9g+ABAAASQ/AAAACJIXgAAIDEEDwAAEBiCB4AACAxZ6U9AEm68MILfenSpWkPAwAAxOCZZ575ubtfVOu9TASPpUuXanx8PO1hAACAGJjZP9V7j6UWAACQmFSDh5ltNLO9J0+eTHMYAAAgIakGD3cfdfdtAwMDaQ4DAAAkhKUWAACQGIIHAABIDMEDAAAkhuABAAASQ/AAAACJIXgAAIDE0McDAAAkhj4eAAD0kOJESWv2/EDLdhzSmj0/UHGilOjvZ+KsFgAA0H7FiZJ2HpzUzOycJKk0PaOdByclSZtWDSUyBmo8AADoESNjU6dDR9nM7JxGxqYSGwMzHgAAdKniREkjY1N6bXpGlwzmVZqeqfm51+pcbweCBwAAXajWsopJ8hqfvWQwn9i4WGoBAKAL1VpWcUlW9bl8f07b169IbFwEDwAAulC95ROXNDSYly389+7NKxMrLJVYagEAoCvVq+kYGszriR2fSGFE85jxAACgC21fv0L5/tyia0kvq9QS+4yHmfVJ+mNJ75c07u5/GfdvAACAxsrLJ5W7WravX5HoskotgYKHme2T9GlJr7v7Ryqub5D0DUk5SX/h7nskXS/pUkm/kHQ89hEDAIBANq0aSj1oVAs647Ff0j2Svl2+YGY5SfdKWqf5gHHEzB6VtELS37v7/zSzRyT9n1hHDABAD6ruyZGF2YtWBAoe7v64mS2tunyVpGPu/pIkmdmDmp/teFXSOwufmRMAAIgkC63O4xKluHRI8yGj7PjCtYOS1pvZn0t6vN6XzWybmY2b2fiJEyciDAMAgO6WhVbncYm9uNTd35b0uQCf2ytpryQVCoVajdQAAOhJWWx1HpcoMx4lSZdVvL504VpgZrbRzPaePHkywjAAAOge5WWV0vSMXO+1Oq8lyVbncYky43FE0nIzW6b5wHGjpJvD3MDdRyWNFgqFrRHGAQBAxyvPctSa3Si3Oq9cHshCT45WBN1O+4CktZIuNLPjkm539/vN7FZJY5rfTrvP3Y+G+XEz2yhp4/DwcLhRAwDQJYoTJd0xelRvvj3b8HPlVuedvqvF3NMvrygUCj4+Pp72MAAASExxoqTt331Ws6eCfT7tVudhmNkz7l6o9R5ntQAAkLBdxUl956lXAn++U5dVakk1eLDUAgDoJUGXVSoNdfCySi2pBg+KSwEAvWJXcVIHnnpFQQsc8v25xI+sTwKn0wIA0GbFiVKo0DGY7+/K0CGx1AIAQFtUNgHrMwscOtZcfoEObL2mrWNLE0stAADEqDhR0h898pzemXsvaswF2EFqkrasXqI7N61s4+jSx64WAABisuW+J/XET98I9Z3BfL++et2Hu3JZpRaWWgAAiCjs9lipd2Y4qrHUAgBABOu+/pj+8fW3An/epI7uPBoVSy0AALRoy31PhgodHzivXxP/5bfbOKLsI3gAABBCK8sq0vxMx+0bPxz/gDoMwQMAgIDCLquUnZ0z/dff+VhPLq1Uo7gUAIAmihMlffGhZ0N/L2fS1z57JYGjAsWlAADUUZwo6UsPPauAB8gusvzi8/X9L62Ne0gdj6UWAABqaHVZRZJu6cFtskERPAAAqPDR2/9W//KruZa+e/cNLKs0Q/AAAGDB0h2HWv7uy3uujXEk3YvgAQDoeVFmOd5/Tk7P37Eh5hF1L3a1AAB62rIdhwKfHFvJJP0ZSyuhsasFANCThnce0rutJA5RyxEFSy0AgJ7SaudRSTo3Z3rxrk/FPKLeQvAAAPSMVpdVJIpH40LwAAB0vSi7VWgEFi+CBwCga0XZrXKWScd2M8sRN4IHAKArtTrLYZJ+xrJK2xA8AABdJUodh0ToaLe+NH/czDaa2d6TJ0+mOQwAQJdYGiF0LL/4fApIE0AfDwBAx6PVeedgqQUA0LGiNAGTCB1pIHgAADpSlFkOOo+mh+ABAOgoBI7ORvAAAHSEKK3OJZZVsoLgAQDIvCizHB9839l6+rZ1MY4GURA8AACZxSxH9yF4AAAypzhR0hcferbl7zPLkV0EDwBApkRZVqHdefbFHjzMbK2kP5Z0VNKD7v5Y3L8BAOg+V9x2WL+ca70pBztWOkOglulmts/MXjezH1dd32BmU2Z2zMx2LFx2Sf8m6VxJx+MdLgCgGy3dcajl0FFudU7o6AxBZzz2S7pH0rfLF8wsJ+leSes0HzCOmNmjkn7k7n9nZh+U9HVJW2IdMQCga0Q5tl6ieLQTBQoe7v64mS2tunyVpGPu/pIkmdmDkq539xcW3n9T0jn17mlm2yRtk6QlS5aEHDYAoJNtue9JPfHTN1r+/prLL9CBrdfEOCIkJUqNx5CkVyteH5d0tZltlrRe0qDmZ0lqcve9kvZKUqFQiHKCMQCgg0QpHpWY5eh0sReXuvtBSQeDfNbMNkraODw8HPcwAAAZQ+CAFLC4tI6SpMsqXl+6cC0wdx91920DAwMRhgEAyDpCB8qizHgckbTczJZpPnDcKOnmWEYFAOgKBA5UCxQ8zOwBSWslXWhmxyXd7u73m9mtksYk5STtc/ejYX6cpRYA6E7rvv6Y/vH1t1r+/i2rl+jOTStjHBGywtzTr+ssFAo+Pj6e9jAAADFglgNm9oy7F2q9l2rLdGY8AKB7EDgQRJTi0sgoLgWA7hAldLz/nByho4dwSBwAoGXMciAsggcAILSogYNj63sXNR4AgFCY5UAUqQYPdx+VNFooFLamOQ4AQHMEDsSBpRYAQENX3/V9/fO/vtPy98/NmV6861MxjgidjKUWAEBdzHIgbiy1AADOcMVth/XLudYbTBI4UA9LLQCARZjlQDsRPAAAkggcSAbBAwB6XNTAIRE6EBzFpQDQw5jlQNIoLgWAHkTgQFpSPSQOAJA8QgfSRI0HAPQIAgeygOABAF0uauBYc/kFOrD1mphGg15HcSkAdDFmOZA1FJcCQBcicCCrWGoBgC6yqzip7zz1SqR7EDrQTgQPAOgSzHKgExA8AKDDETjQSejjAQAdjNCBTsOMBwB0IAIHOhXBAwA6yLIdh+QR70HoQJro4wEAHYJZDnQD+ngAQMYRONBNKC4FgAwjdKDbUOMBAAkqTpQ0Mjal16ZndMlgXtvXr9CmVUNnfI7AgW5F8ACAhBQnStp5cFIzs3OSpNL0jHYenJSk0+EjauA4y6Rju2uHjqChB2gnggcAJGRkbOp06CibmZ3TyNiUNq0aaussR5DQAySB4AEACXlteqbm9dL0TKTQEWRZpVnoAZJCcSkAJOSSwXzs9wxay1Ev9NS7DrQLwQMAErJ9/Qrl+3Ox3OvlPdeGKiCtF3raEYaARggeAJCQTauGzljuCOvuG65sacdKrdCT789p+/oVkcYDhNWWGg8zO1/S30n6qrv/dTt+AwA6TZpbZMt1HOxqQdoCBQ8z2yfp05Jed/ePVFzfIOkbknKS/sLd9yy89RVJD8c8VgDoSFEDx903XBlLQNi0aoiggdQFnfHYL+keSd8uXzCznKR7Ja2TdFzSETN7VNKQpBcknRvrSAGgw1xx22H9ci7akW5xhQ4gKwIFD3d/3MyWVl2+StIxd39JkszsQUnXS/p3ks6X9CFJM2Z22N1PxTdkAMi+rMxyAFkTpcZjSNKrFa+PS7ra3W+VJDP7PUk/rxc6zGybpG2StGTJkgjDAIDsaHcTMGo00Ona1kDM3fc3eX+vpL2SVCgUos1FAkAG0HkUaC5K8ChJuqzi9aUL1wIzs42SNg4PD0cYBgCkK4ndKnQeRbeIEjyOSFpuZss0HzhulHRzmBu4+6ik0UKhsDXCOAAgFUke6Fai8yi6RNDttA9IWivpQjM7Lul2d7/fzG6VNKb57bT73P1o20YKABnSruLR4kRJX/ne8/rVu++Vx5WmZ2SSaq1J03kUnSborpab6lw/LOlwqz/OUguAThM1cAzVKQotTpT01UePanpmtub3XDojfNB5FJ0o1dNpWWoBkKQou0I+evvf6l9+Fa3deb1ajl3FSX3nqVeaft81H1zY1YJOlmrwYMYDQFKi7AppV/FocaKkP3zo2ZpLKLUMDeb1xI5PRBoLkDZmPAD0hFZ2hUQNHLesXqI7N62s+d6W+57UEz99I9T9WFZBN0g1eABAUurt/qh3vZ2zHF9++FmF7aS+5vILWFZBV2CpBUBPqLcltXpXSLsCR9A6jmomaUuDmROg0/Sl+ePuPuru2wYGBtIcBoAesH39CuX7c4uuVe4KWff1xzIXOm5ZvUQ/23MtoQNdhaUWAD2hvExRa1dL1gKH1Lg+BOhk5p7+MSmFQsHHx8fTHgaAHtPOVuet3vuD7ztbT9+2rtUhAZlgZs+4e6HWe9R4AOgaYfp0ZG2WI2fS1z5bu5sp0E2Y8QDQFar7dEjzNRy7N69c9Jd51gKHJC2/+Hx9/0trI4wKyJbMzngAQFya9emIGjjWXH6BDmy9puZ7Ue5NLQd6DcEDQFdo1KejXbMcrbZRz/f3affmj7Ksgp5EjQeArlCvT0eUxeRGxaPDOw/p3RZuzgwHeh01HgC6Qq0ajyjuvuHKRYWqv3nFRfrhiydqhpsgTNLPGgQZoJtQ4wGg65WXLb740LOR7vPynmtrHijXauGoxCwHUIngAaArxHmgW61C1VbdfQNbZIFKBA8AHS/u4tF6haphnJszvXjXpyLfB+g2BA8AHatdu1XO7e/TzOyp2O8LgF0tADpQq9tYy95/Tk7P37Gh5ntRwkyjXh8A5qUaPNx9VNJooVDYmuY4AHSOds1yXHHbYf1yrrVdfhSPAsGx1AKgI7QrcBQnSpF2wlA8CoRD8ACQee0KHa02AZNYVgFaRfAAkFlZPNCt0X0BNEfwAJA5677+mP7x9bda/n67DnRjlgOIjuABIFPaNctx9V3f1z//6zux3xdAOAQPAJmQ1eLRXJ/pa7/7sZa/D2Ax+ngASFXUYNDo8LWoYWZoMK/t61ewawWIEX08AKSmXbMccQSOJ3Z8ItI9ANTGUguAxG2570k98dM3Wv5+o3qLqKFDkn7ziosi3wNAbQQPAInK6ixHpR++eCK2ewFYjOABoGXFiZJGxqb02vSMLmlSD9GuwBF1620tcZxOC6A2ggeAlhQnStp5cFIzs/OHtZWmZ7Tz4KQkLQofUYNBuw50W37x+Xr7nVMq1QgZlwzmW74vgMYIHgBaMjI2dTp0lM3MzmlkbOp08Mjqskr5vvU6mFLjAbQPwQNAS+otR7w2PdO2luRRt95Wdx6tV8tBjQfQPgQPAC25ZDBfc5nCpUihwySt2fODM+pF2jF70ig8AWgPggeAlmxfv2JRjUdU+f6cZmbn5FpcLxJlhkNqvPW2XniixgNon764b2hmv2Fm3zKzR8zsC3HfH0A2bFo1pM98PJ6OnibVrBeJGjqsyfvb169Qvj+36Fq+P6ft61dE+l0A9QUKHma2z8xeN7MfV13fYGZTZnbMzHZIkrv/xN0/L+mzktbEP2QAWfHA060vqVTyWO5ypmYzF5tWDWn35pUaGszLNN+xdPfmlbRIB9oo6FLLfkn3SPp2+YKZ5STdK2mdpOOSjpjZo+7+gpldJ+kLkv5XvMMFkAVRT3pNQtCZi02rhggaQIICzXi4++OSqvsbXyXpmLu/5O7vSHpQ0vULn3/U3T8paUucgwWQvqU7DrUcOs7NmYbaVD9x9w1XMnMBdIAoxaVDkl6teH1c0tVmtlbSZknnSDpc78tmtk3SNklasmRJhGEASELURmDlIs/qxmNRvbzn2lAdVAGkK/ZdLe7+mKTHAnxur6S9klQoFNq1xAsgorh7cpQDwcjYVM0dJWHvHbSDKoBsiBI8SpIuq3h96cK1wMxso6SNw8PDEYYBoF2ihI5zc6YX7/pUzffi3CJbr4Pqlx9+Tn/40LPMgAAZEyV4HJG03MyWaT5w3Cjp5jA3cPdRSaOFQmFrhHEAiFlWj61ffvH5+v6X1i66Vq/Z15zPT6QyAwJkS6DgYWYPSFor6UIzOy7pdne/38xulTQmKSdpn7sfDfPjzHgA2RMlGNyyeonu3LQy9vtK9cNMvSZglarPkAGQHnNPv7yiUCj4+Ph42sMAelqU4tHqM1AqtStwlAUtVjVJP2tyLwDxMLNn3L1Q6z1apgM9LsrBa7WWPipFCR1Bg0Jlsepr0zPqMzu9zFKJNuhANqQaPFhqAdL10dv/Vv/yq9a2td59w5V1ly7aPctRrbIJWK0ZENqgA9mRavCguBRIR5Ti0UazHO0sSg2qegaEXS1AtrDUAvSQKMsqH3zf2Xr6tnV13096lqMR2qAD2cVSC9AjovTkaFQ8GmW5Roo3cNDBFMg+drUAXa44UdIdo0f15tuzLX2/XuiI2tG00dbbVtSr7eDMFiB57GoBelTUmgtJevkXZ/bIWLbjUKSj7OOc5Sir18GU/h1AthA8gC4VR+iQFncGvfqu77d8Mq3UnsBRVq+Dab3rANJBjQfQRco1Dq0cvmZSzVmMcv+LKMWjZ5l0bHd7m3fV62BK/w4gW/rS/HF3H3X3bQMDA2kOA+gKxYmSvvzd50KHjuUXn6+X91yrP7vhSuX7c4vey/fn9M8nZyKFjpf3XNv20CFJ29evqDl++ncA2cJSC9AFWllW6TPp5qvfK/Cs7n+R7+/T203akDfSzmWVWujfAXQGdrUAHazV81UadR2VpCtuO6xfzrX2z4a4d6sA6DyZ3dVCjQfQuuGdh/RuyGzQ3yeN/G790BGlwVgSdRwAOh8t04EO00r/jKEAyw5RdqwwywEgKGo8gA7SytJKs1AQZZajUUfT8r2puQBQieABZFyUDqHNQkerNSJS8+LR6k6ipekZ7Tw4KUmED6CHETyADGs1dDSbiYgSOBqdTluJTqIAaiF4ABlUnCjptr+a1FvvhNvO2qzAM0o30/efk9Pzd2wI/Hk6iQKohV0tQMaUG4HNnQq3ZaXRTESUOg6p+fbbWrUcdBIFUAt9PICMmK+JeF4zs6dCfa/Z0keU3SrNlmyk+qfCfubjQ/reMyVOiwV6UGb7eACY12rNRaPi0ShFqR9839l6+rZ1gT5br5bjhy+e0O7NK9nVAmARggeQkuJESXeMHtWbb8+G/m6zYNBq6Ogz6eufbbysUq1RLcemVUMEDQCLEDyAFBQnStr+yHOaDdmWPEijrlZnT4Isq9RCLQeAMAgeQApGxqZChQ6TtKVJ6IiyY6VZ8Wgj29evqFnjwamwAGoheAAJKu/+CHN0fbNZjiiBI2hPjkY4FRZAGAQPIAG7ipM68PQrCruJrF2dR6PMcNRCLQeAoOjjAbRRq1tZg5yB8tVHj2p6JlxhahwzHAAQBafTAm3QSsOuwXy/vnrdh5vOHLQrzABAElhqAWLUSqvzocG8ntjxiaafa3WLbLOtt5wgCyBJBA8gJq0EgyC7P4oTJf3RI8/pnZBbb6Vgrc45QRZAkggeQAyKEyUdCBk6zuvv0580aB/eah2HFHxZhRNkASSN4AG0qHKJos9MYeYj2rVbJWidSBknyAJIGsEDaEH1EsVcwH2y5+ZML971qbrvt9qTI8zZKpXoOgogaX1pDwDoNLuKk/riQ8+esUTRzC2rl7QldCy/+PyWQoc033U0359bdI2uowDaiRkPIKBWgsF8HcdHmxZ4hu1mKsWzPZauowCSRvAAAggaOnJmOuUe6C/w+eWa5zUzeyr0eIIcFhcUXUcBJKktwcPMNkm6VtL7Jd3v7v+7Hb8DJGFXcTJQ6Mj357S7wS6VSq0uqwwxIwGgwwUOHma2T9KnJb3u7h+puL5B0jck5ST9hbvvcfeipKKZfUDSf5NE8EBHCtObo52hg66jALpFmBmP/ZLukfTt8gUzy0m6V9I6ScclHTGzR939hYWP7Fp4H+hIDzz9aqDP3bJ6SdNllTtGj+rNt8P15CBwAOg2gYOHuz9uZkurLl8l6Zi7vyRJZvagpOvN7CeS9kj6G3f/h7gGCyQtyDbZZvUWYTuamqQ/i/n0WADIiqg1HkOSKv+V8LikqyX9gaTfkjRgZsPu/q3qL5rZNknbJGnJkiURhwG0R86sbvhoNhvR6tkqW5rMngBAJ2tLcam7f1PSN5t8Zq+kvZJUKBTCH0IBRLR0x6Ezrr2859pFr2+6+rKa4aHRLMeu4qQOPPVKqE6mknTOWX3608803noLAJ0uagOxkqTLKl5funAtEDPbaGZ7T548GXEYQDi1Qket63duWqlbVi9RzkzS/AxIs9DxnRZCx5rLL9DUnZ8kdADoelFnPI5IWm5myzQfOG6UdHPQL7v7qKTRQqGwNeI4gMCKE4GzsaT58NGsZ0arB7p94Lx+3b4x+NkqANDpwmynfUDSWkkXmtlxSbe7+/1mdqukMc1vp93n7kdD3HOjpI3Dw8PhRg20qHzGStz33P7d5zR7Kvg8R76/T7ubdDQFgG4UZlfLTXWuH5Z0uJUfZ8YDSShOlPTFh55t2/1HxqZChY44u44CQKfhkDh0tXaHDincEfKEDgC9LtWzWlhqQbuNjE2F+nz1rpZq5QPdKg9Uq3e0fCVanQPAPPMADZLarVAo+Pj4eNrDQBdatuNQ0x0mQc5YKU6U9J8PPq+3qw50y/fn9JmPD+mh//vqGcst/TnTyO98jLABoOeY2TPuXqj1HqfToitUHi1fbvo1NJjXQL6/4U6TZjMRzc5VmZmd0w9fPKGR3/3Yol0t7FYBgNpYakHHK+9UmZmdk/Rem/PS9Iz6c9bwu0/s+ETd94Ie5vba9AxHywNAQKkWl7r7qLtvGxgYSHMY6HAjY1OnQ0e12TnXB87rr/les3qOoCfIXjKYD/Q5AABLLegCzXaVTL892zRklFUWjwZhkravXxHoswAAttOiCzSbcQg6I1FesilNzwRuec6BbgAQDjUe6EiVMxOD5/Wrv89qNvHK9+cCz0g0WrKpdl5/n/6EzqMAEBo1Hug41TMTb749K5k0mJ+v5Sgf6DY0mG+6TbZS0OWVW1Yv0Qt/zIFuANAKajzQcWrNTMzOuc4/5yw9e/tvB7pHmEZgOTOdcj/9OQIHALSO4IGOU29mIuiMRfX229L0jHYenNRnPj6k7z1TWhRqgjQXAwAER40HOk69mYlGRaSVMxx9Cw3GKpUbge3evPKMmRBCBwDEh5bpyIxdxUk98PSrmnNXzkw3XX1ZzQPVqmcspPozE8WJkr7yvef1q3dPVd/mDCbpZwG33QIA6qNlOjJvV3FS33nqldOv59xPv64OH+Vw0WxmojhR0pe/+5zmAh5ZTyMwAGg/ggcy4YGnX617vdasR7MW5cWJkr788HNnLKnUE2bbLQCgdQQPZEK9gBA0OFQqL8U0+y67VQAgeQQPZEKuRsFn+XoQzYpHa/naZzmyHgCSlmoDMTPbaGZ7T548meYwkAE3XX1ZqOuVqhuKBQkday6/gNABACmgcyky4c5NK3XL6iWnZzhyZrpl9ZKa9R3VwrQ6N813Hj2w9ZoowwUAtIilFmTGnZtWBgoa1YI0DqMRGABkA6fTouPV2wabM5Mp/JktAID2YcYDHW/7+hWBG4oBANJF8EBsah28lsRf/EEbigEA0kfwQCzqHbwmqeUAUJwo6Y7Ro/PH3mv+2PuvXvfhmvdr1lAMAJAN1HggFrV2lszMzmlkbKql+xUnStr+yHOnQ4ckTc/Mavt3n1NxohRprACA9NDHA7GIelR9tZGxKc3OndmPY/aUtxxmAADpS3Wpxd1HJY0WCoWtaY4DZwpbr9HKUfWNfq/WvcpaDTMAgPRR44EztFKvUW9nSbOD14oTJd32V5N66533vleanpFJqtd/lFNkAaBzUeOBM7RSr7Fp1ZB2b16pocF84N4Zu4qT+uJDzy4KHWX1Qkd/n3GKLAB0MGY8cIZW6zXC7CwpTpR04KlXmn7uA+f1B9rVAgDoDAQPnOGsPmn21JnX41ziGBmbqjurUTY0mNcTOz4R228CANJH8MAiW+57smbokBR5iaOygLRZ6LAYfg8AkD0EDyzyxE/fqPtelCWO6oLVZrasXsKSCgB0IYIHEhH06Pp8f592b/4ooQMAuhTBA20Rpi+HSZyvAgA9IvbgYWa/Luk2SQPu/jtx3x/ttebyC2out6y5/IKm3y2Hjeo+HI36clBACgC9JVAfDzPbZ2avm9mPq65vMLMpMztmZjskyd1fcvfPtWOwaL8DW685I2SsufwCHdh6TcPvlWs4yjMb1SHDNT+zUSlIgzEAQHcJOuOxX9I9kr5dvmBmOUn3Slon6bikI2b2qLu/EPcgkaxmIaOWIDUcrvkZDo6uB4DeFSh4uPvjZra06vJVko65+0uSZGYPSrpeEsGjBwU5P4VlFQBAlJbpQ5JerXh9XNKQmf2amX1L0ioz21nvy2a2zczGzWz8xIkTEYaBLGjWXIxlFQCA1IbiUnf/haTPB/jcXkl7JalQKDTrJ4WMqHdqba1D4soFpUMsqwAAFkQJHiVJl1W8vnThWmBmtlHSxuHh4QjDQFKCnFpbK5QAAFBm7sEmGxZqPP7a3T+y8PosSf9P0n/UfOA4Iulmdz8adhCFQsHHx8fDfg0JW7PnBzX7cVC7AQCoZGbPuHuh1ntBt9M+IOlJSSvM7LiZfc7d35V0q6QxST+R9HDY0GFmG81s78mTJ8N8DSlp9dRaAADKgu5quanO9cOSDrf64+4+Kmm0UChsbfUeSE69DqRxnloLAOhuUXa1oMdsX79C+f7comvsVgEAhJHqWS0Ul3YWCkgBAFEFLi5tJ4pL01NveywAAK1qVFzK6bQ9bFdxUgeeemXRYW7V22MBAIhTqjUe7GpJT3GitCh0lM3MzmlkbCqVMQEAul+qwcPdR91928DAQJrD6EkjY1M1j6mX2B4LAGgfdrX0qEbhgu2xAIB2YamlR9ULFyaxPRYA0DYstfSoWj05TNKW1UsoLAUAtA27WnoUPTkAAGkgePSwTauGCBoAgERRXAoAABJDcSkAAEgMxaUAACAxLLUAAIDEEDwAAEBiCB4AACAxFJcCAIDEUFyaYcWJktbs+YGW7TikNXt+oOJEKe0hAQAQCQ3EMqo4UdLOg5OamZ2TJJWmZ7Tz4KQk0fQLANCxqPHIqJGxqdOho2xmdk4jY1MpjQgAgOgIHhlV79j6RsfZAwCQdQSPjKp3bH296wAAdAKCR0bVOrY+35/T9vUrUhoRAADRUVyaURxbDwDoRgSPOooTpbb8pR/mvhxbDwDoNqkGDzPbKGnj8PBwmsM4Q9xbWcthozQ9I5PkC9fZIgsA6DU0EKshzq2s5RBTWtiN4lXvs0UWANBLKC6tIc6trLVCTBz3BQCgExE8aohzK2uQUMEWWQBAryB41BDnVtZmoYItsgCAXkLwqGHTqiHt3rxSQ4N5maShwbx2b17ZUgForRBjC/8d5b4AAHQittPWEddWVvpxAADwHoJHAujHAQDAPJZaAABAYggeAAAgMbEvtZjZ+ZL+u6R3JD3m7gfi/g0AANCZAs14mNk+M3vdzH5cdX2DmU2Z2TEz27FwebOkR9x9q6TrYh4vAADoYEGXWvZL2lB5wcxyku6V9ElJH5J0k5l9SNKlkl5d+Fjjlp0AAKCnBAoe7v64pDeqLl8l6Zi7v+Tu70h6UNL1ko5rPnw0vL+ZbTOzcTMbP3HiRPiRAwCAjhOluHRI781sSPOBY0jSQUmfMbP/IWm03pfdfa+7F9y9cNFFF0UYBgAA6BSxF5e6+1uSfj/IZ81so6SNw8PDcQ8DAABkUJQZj5KkyypeX7pwLTB3H3X3bQMDAxGGAQAAOkWU4HFE0nIzW2ZmZ0u6UdKj8QwLAAB0o6DbaR+Q9KSkFWZ23Mw+5+7vSrpV0pikn0h62N2PhvlxM9toZntPnjwZdtwAAKADmbunPQYVCgUfHx9PexgAACAGZvaMuxdqvZdqy3RmPAAA6C2pBg+KSwEA6C2xb6fNiuJESSNjU3ptekaXDOa1ff0KjqYHACBlqQaPdvXxKE6UtPPgpGZm5zu2l6ZntPPgpCQRPgAASFFXLrWMjE2dDh1lM7NzGhmbivV3AABAOKkGj3Z5bXom1HUAAJCMrgwelwzmQ10HAADJ6MrttNvXr1C+P7foWr4/p+3rV8T6OwAAIJyurPHYtGpIuzev1NBgXiZpaDCv3ZtXUlgKAEDKunY77aZVQwQNAAAypitrPAAAQDYRPAAAQGK6srgUAABkU1cWlwIAgGxiqQUAACSG4AEAABJD8AAAAImhuBQAACSG4lIAAJAYlloAAEBizN3THoPM7ISkf1p4OSCpeu2l2bXq9y+U9POYh1lvHHF8p9Fn6r3Hcwr2XpDn1Ow1zynYa55TsNc8p+av2/WM6o0tju/wnBZ/59+7+0U1P+XumfqPpL1hr1W/L2k8qbHF8Z1Gn6n3Hs8pvucU4DXPiefEc0rwObXrGfGc0n9O7p7JpZbRFq7Ver8dWvmdIN9p9Jl67/Gcgr0X5Dk1e90uPKdgeE7B8JyC4TkF067nlI2llriZ2bi7F9IeR9bxnILhOQXDcwqG59QczyiYTn1OWZzxiMPetAfQIXhOwfCcguE5BcNzao5nFExHPqeunPEAAADZ1K0zHgAAIIMIHgAAIDEEDwAAkJiuDx5mdr6Z/aWZ3WdmW9IeT1aZ2a+b2f1m9kjaY8kyM9u08GfpITP77bTHk1Vm9htm9i0ze8TMvpD2eLJs4Z9R42b26bTHklVmttbMfrTwZ2pt2uPJKjPrM7O7zOzPzew/pT2eejoyeJjZPjN73cx+XHV9g5lNmdkxM9uxcHmzpEfcfauk6xIfbIrCPCd3f8ndP5fOSNMV8jkVF/4sfV7SDWmMNy0hn9NP3P3zkj4raU0a401LyH8+SdJXJD2c7CjTF/I5uaR/k3SupONJjzVNIZ/T9ZIulTSrDD+njgwekvZL2lB5wcxyku6V9ElJH5J0k5l9SPP/J7y68LG5BMeYBfsV/Dn1sv0K/5x2LbzfS/YrxHMys+skHZJ0ONlhpm6/Aj4nM1sn6QVJryc9yAzYr+B/nn7k7p/UfEi7I+Fxpm2/gj+nFZL+3t2/JCmzM40dGTzc/XFJb1RdvkrSsYV/c39H0oOaT3/HNR8+pA7939uqkM+pZ4V5TjbvTyX9jbv/Q9JjTVPYP0/u/ujCXxY9tcQZ8jmtlbRa0s2StppZz/wzKsxzcvdTC++/KemcBIeZuhb+vntz4TOZ/Rfts9IeQIyG9N7MhjT/f8DVkr4p6R4zu1bJtZrNsprPycx+TdJdklaZ2U53353K6LKj3p+nP5D0W5IGzGzY3b+VxuAypN6fp7WaX+Y8R70341FLzefk7rdKkpn9nqSfV/wF26vq/XnaLGm9pEFJ96Qwrqyp98+nb0j6czP7D5IeT2NgQXRT8KjJ3d+S9PtpjyPr3P0Xmq9bQAPu/k3Nh1k04O6PSXos5WF0DHffn/YYsszdD0o6mPY4ss7d35aU+Vq9bprWK0m6rOL1pQvXsBjPKRieUzA8p2B4TsHwnILp6OfUTcHjiKTlZrbMzM6WdKOkR1MeUxbxnILhOQXDcwqG5xQMzymYjn5OHRk8zOwBSU9KWmFmx83sc+7+rqRbJY1J+omkh939aJrjTBvPKRieUzA8p2B4TsHwnILpxufEIXEAACAxHTnjAQAAOhPBAwAAJIbgAQAAEkPwAAAAiSF4AACAxBA8AABAYggeAAAgMQQPAACQGIIHAABIzP8HzpPmFaYyiuUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correct the sars_cov2_gc_l_mean here..\n",
    "df_ww['sars_c'] = df_ww['sars_cov2_gc_l_mean']/df_ww['raw_ansis_sars_repc_mean']\n",
    "df_ww['sars_cov2_gc_l_mean_v2'] = df_ww['raw_ansis_sars_repc_mean_v2']*df_ww['sars_c']\n",
    "# scatter plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.scatter(df_ww['sars_cov2_gc_l_mean_v2'],df_ww['sars_cov2_gc_l_mean'])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.savefig(f'{ww.data_dir}/check_gc_l.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2ad12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-define the gc_cl here\n",
    "df_ww['sars_cov2_gc_l_mean'] = df_ww['sars_cov2_gc_l_mean_v2']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6f76b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/wastewater/lib/python3.8/site-packages/geopandas/geodataframe.py:577: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n",
      "/tmp/ipykernel_26081/4248926751.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_ww = df_ww.drop('ww_catchment_code', 1)\n",
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/preprocessing.py:540: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  df_diagnostic = pd.concat([diag, diag2, diag3, diag4, diag5], 1)\n"
     ]
    }
   ],
   "source": [
    "# add area (function would be good)\n",
    "gdf_catch = gpd.read_file('s3://dash-879281191186-prod-s3-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_dataset_staging/ww_ons/20201120_ONS_WW_ENGLAND_CATCHMENT_BOUNDARIES.csv')\n",
    "gdf_catch.set_crs(epsg=27700, inplace=True, allow_override=True)\n",
    "gdf_catch = gdf_catch.to_crs('epsg:3857')\n",
    "df_ww = df_ww.merge(gdf_catch.set_index('CATCHMENT_CODE').geometry.area.reset_index().rename(columns={'CATCHMENT_CODE':'ww_catchment_code', 0:'catchment_area'}))\n",
    "df_ww = df_ww.drop('ww_catchment_code', 1)\n",
    "df_ww.catchment_area /= 1e6 # in km\n",
    "\n",
    "df_ww, _ = ww.impute_ww(df_ww)\n",
    "df_ww  = df_ww.rename(columns={'date_sample_collected': 'date'})\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_8_dec21.csv') # example saving to data_dir\n",
    "# df_diagnostic.to_csv(f'{ww.data_dir}/diag_data_8_dec21.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85f73584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4900703783708452"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_ww.grab_compo_ind == 'Composite').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11809e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/data/loading_lookups.py:93: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_lookup = df_lookup.drop(['CATCHMENT_CODE', 'CATCHMENT_NAME'], 1)\n",
      "/home/ec2-user/SageMaker/jbc-wastewater-analysis/wastewater/data/loading_lookups.py:103: UserWarning: This dataset needs to be ingested properly: jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/ukmidyearestimates20192019ladcodes.xls\n",
      "  warnings.warn('This dataset needs to be ingested properly: jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/ukmidyearestimates20192019ladcodes.xls')\n",
      "/tmp/ipykernel_26081/3281686484.py:14: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  subregions_pop = df_lookup.loc[df_lookup.CIS20CD.isin(df_ww.CIS20CD)\n"
     ]
    }
   ],
   "source": [
    "threshold = 1 / 1000\n",
    "df_lookup = ww.load_cis_to_site_lookup()\n",
    "\n",
    "# select sites whose population is at least 1/1000 of the subregion\n",
    "df_lookup = df_lookup[df_lookup.catch_in_cis_prop > threshold]  \n",
    "\n",
    "\n",
    "# Add lookup CIS regions info\n",
    "df_ww = df_ww.merge(df_lookup[['CIS20CD','ww_site_code', 'catch_in_cis_prop', 'catch_cis_population']] , \n",
    "                    on='ww_site_code', how='inner')\n",
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_9_dec21.csv') #\n",
    "\n",
    "# getting the populations\n",
    "subregions_pop = df_lookup.loc[df_lookup.CIS20CD.isin(df_ww.CIS20CD) \n",
    "                 & df_lookup.ww_site_code.isin(df_ww.ww_site_code)]\\\n",
    "                 .groupby('CIS20CD')['catch_in_cis_prop','catch_cis_population'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b191a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export preprocessed WW dataset before aggregating to CIS subregions\n",
    "# save = True #False\n",
    "# bucket = \"s3://jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/cis_results\"\n",
    "# if save:\n",
    "#     df_ww.to_csv(bucket+'/df_ww_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c38be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 83)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ww.ww_site_code.nunique(), len(set(subregions_pop.CIS20CD.unique()).intersection(df_ww.CIS20CD.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba647dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw_ansis_sars_repc_1</th>\n",
       "      <td>38800.0</td>\n",
       "      <td>89.978092</td>\n",
       "      <td>275.183187</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>13.60600</td>\n",
       "      <td>55.298849</td>\n",
       "      <td>5.059119e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_ansis_sars_repc_2</th>\n",
       "      <td>38800.0</td>\n",
       "      <td>92.556479</td>\n",
       "      <td>302.973243</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>1.652000</td>\n",
       "      <td>12.15620</td>\n",
       "      <td>54.914001</td>\n",
       "      <td>6.798662e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_ansis_sars_repc_mean</th>\n",
       "      <td>38800.0</td>\n",
       "      <td>113.620171</td>\n",
       "      <td>388.600951</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.778340</td>\n",
       "      <td>14.35500</td>\n",
       "      <td>63.075001</td>\n",
       "      <td>9.425240e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_ansis_sars_repc_std</th>\n",
       "      <td>38800.0</td>\n",
       "      <td>-2.544020</td>\n",
       "      <td>1.030282</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.560000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sars_cov2_gc_l_mean</th>\n",
       "      <td>38800.0</td>\n",
       "      <td>24177.217192</td>\n",
       "      <td>52493.655198</td>\n",
       "      <td>-6.623212</td>\n",
       "      <td>1955.199951</td>\n",
       "      <td>7085.31338</td>\n",
       "      <td>22693.250977</td>\n",
       "      <td>1.647030e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std       min  \\\n",
       "raw_ansis_sars_repc_1     38800.0     89.978092    275.183187 -4.000000   \n",
       "raw_ansis_sars_repc_2     38800.0     92.556479    302.973243 -4.000000   \n",
       "raw_ansis_sars_repc_mean  38800.0    113.620171    388.600951 -4.000000   \n",
       "raw_ansis_sars_repc_std   38800.0     -2.544020      1.030282 -3.000000   \n",
       "sars_cov2_gc_l_mean       38800.0  24177.217192  52493.655198 -6.623212   \n",
       "\n",
       "                                  25%         50%           75%           max  \n",
       "raw_ansis_sars_repc_1        2.680000    13.60600     55.298849  5.059119e+03  \n",
       "raw_ansis_sars_repc_2        1.652000    12.15620     54.914001  6.798662e+03  \n",
       "raw_ansis_sars_repc_mean     2.778340    14.35500     63.075001  9.425240e+03  \n",
       "raw_ansis_sars_repc_std     -3.000000    -3.00000     -3.000000  8.560000e+00  \n",
       "sars_cov2_gc_l_mean       1955.199951  7085.31338  22693.250977  1.647030e+06  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ww.describe()[['raw_ansis_sars_repc_1', 'raw_ansis_sars_repc_2',\n",
    "                    'raw_ansis_sars_repc_mean','raw_ansis_sars_repc_std','sars_cov2_gc_l_mean',]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe9b63a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cis_population removed.\n"
     ]
    }
   ],
   "source": [
    "sample_variables = ['sars_cov2_gc_l_mean', \n",
    "                    'suspended_solids_mg_l', 'ammonia_mg_l', 'ophosph_mg_l', \n",
    "                    'sample_ph_pre_ansis', \n",
    "                    'control_gc_l_mean','reac_vol_control', # \"reac_vol_sars\", \n",
    "                    'raw_ansis_sars_repc_1', 'raw_ansis_sars_repc_2',\n",
    "                    'raw_ansis_sars_repc_mean','raw_ansis_sars_repc_std',\n",
    "                    'compo_frac',\n",
    "                    'sars_below_lod', 'sars_below_loq', \n",
    "                    'reception_delay',\n",
    "#                    'ww_site_code',  # try here?\n",
    "#                     'date',\n",
    "#                   'analysis_lab_code',\n",
    "                     #'lab_analysis_1.1.1', 'lab_analysis_1.1.2',\n",
    "                     #'target_gene_N1'\n",
    "                   ]\n",
    "\n",
    "site_variables = [\n",
    "                  'catchment_population_ons_mid_2019',\n",
    "                  'catchment_area',\n",
    "                    'site_skey',  # numeric so should be ok.\n",
    "#                    'ww_site_code',\n",
    "#                   'water_company_AE',\n",
    "#                   'water_company_AW', 'water_company_NW', 'water_company_ST',\n",
    "#                   'water_company_SW', 'water_company_SWS', 'water_company_TW',\n",
    "#                   'water_company_UU', 'water_company_WW', 'water_company_WXW',\n",
    "#                   'water_company_YW'\n",
    "]\n",
    "\n",
    "cis_variables = ['catch_in_cis_prop', 'catch_cis_population', 'cis_population']\n",
    "\n",
    "all_variables = sample_variables + site_variables + cis_variables\n",
    "\n",
    "for var in all_variables:\n",
    "    if var not in df_ww:\n",
    "        print(var, 'removed.')\n",
    "        all_variables.remove(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "224699ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('catch_in_cis_prop', 'cis_population')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sars_cov2_gc_l_mean', \n",
    "'suspended_solids_mg_l', \n",
    "'ammonia_mg_l', \n",
    "'ophosph_mg_l', \n",
    "'sample_ph_pre_ansis', \n",
    "'control_gc_l_mean',\n",
    "'compo_frac',\n",
    "'sars_below_lod', 'sars_below_loq', \n",
    "'reception_delay'\n",
    "'catchment_population_ons_mid_2019','catchment_area',\n",
    "'catch_in_cis_prop',  'cis_population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9d7091b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26081/3114940664.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_ww_agg = df_ww_agg.drop(['catch_in_cis_prop','catch_cis_population'], 1).merge(subregions_pop)\n"
     ]
    }
   ],
   "source": [
    "def weighted_agg(variables, weight_column, agg_function):\n",
    "    def fn(s):\n",
    "        weights = s[weight_column]\n",
    "        return pd.Series({ col : np.average(s[col], weights=weights) for col in variables})\n",
    "    return fn\n",
    "\n",
    "weighted_avg = weighted_agg(all_variables, 'catch_cis_population', np.nansum)\n",
    "\n",
    "df_ww_agg = df_ww.groupby(['CIS20CD', 'date']).apply(weighted_avg).reset_index()\n",
    "df_ww_agg = df_ww_agg.drop(['catch_in_cis_prop','catch_cis_population'], 1).merge(subregions_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c7d8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cis data\n",
    "df = df_ww_agg.merge(df_cis_interpolated, how='inner').sort_values(['CIS20CD', 'date'])  # change for left\n",
    "df = df.dropna(subset=['CIS20CD', 'date'])\n",
    "\n",
    "df.CIS20CD.nunique()\n",
    "\n",
    "df_total = df_ww_agg.merge(df_cis_interpolated, how='left').sort_values(['CIS20CD', 'date'])  # change for left\n",
    "df_total = df_total.dropna(subset=['CIS20CD', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2ebdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ww.to_csv(f'{ww.data_dir}/raw_data_10_cis_dec21.csv') #\n",
    "# 'df' has fewer variables...than 'df_ww'\n",
    "df.to_csv(f'{ww.data_dir}/raw_data_11_cis_dec21.csv') #\n",
    "# export_dataset = False\n",
    "# if export_dataset:\n",
    "#     df.to_csv(ww.output_dir+'/df_ww_cis.csv', index=False)\n",
    "#     df.to_csv('s3://jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/df_ww_cis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e8740",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from wastewater.ml_utils import RandomIntercepts, RandomEffects\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "dict_models = dict(lr = LinearRegression(),\n",
    "                   xgb = XGBRegressor(),\n",
    "                   ri = RandomIntercepts('CIS20CD'),\n",
    "                   re = RandomEffects('CIS20CD', \n",
    "#                                       slope_vars=['sars_cov2_gc_l_mean'], \n",
    "                                      correlated_re=False))\n",
    "\n",
    "model_variables = dict(lr = all_variables,\n",
    "                       xgb = all_variables,\n",
    "                       ri =  ['sars_cov2_gc_l_mean', #'control_gc_l_mean', #'reac_vol_control', \n",
    "                             'suspended_solids_mg_l', 'ammonia_mg_l', 'ophosph_mg_l', \n",
    "                             'sample_ph_pre_ansis', \n",
    "                              \n",
    "                              'compo_frac',\n",
    "                             'sars_below_lod', \n",
    "                              'sars_below_loq'\n",
    "                             ],\n",
    "                       re = ['sars_cov2_gc_l_mean', #'control_gc_l_mean', # 'reac_vol_control', \n",
    "                             'suspended_solids_mg_l', 'ammonia_mg_l', 'ophosph_mg_l', \n",
    "                             'sample_ph_pre_ansis', \n",
    "                             'compo_frac',\n",
    "                             'sars_below_lod', \n",
    "                             'sars_below_loq'\n",
    "                            ]\n",
    "                      )\n",
    "\n",
    "# model_variables = dict(lr=['sars_cov2_gc_l_mean'],\n",
    "#                        xgb=['sars_cov2_gc_l_mean'],\n",
    "#                        ri=['sars_cov2_gc_l_mean'],\n",
    "#                        re=['sars_cov2_gc_l_mean'])\n",
    "\n",
    "model_labels = {'lr': 'Linear Regression', 'ri': 'Random Intercepts', \n",
    "                're': 'Random Effects','xgb': 'Gradient Boosted',\n",
    "               'process': 'Process-based'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb98d1c",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "compute_mae = lambda y, pred: np.abs(pred-y).mean()\n",
    "compute_mae_natural = lambda y, pred: np.abs(10**pred-10**y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48425958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap predictions\n",
    "from wastewater.ml_utils import bootstrap\n",
    "\n",
    "repeat = 50\n",
    "preds_bootstrap = {}\n",
    "\n",
    "models = ['lr', 'ri','re', 'xgb'] # remove some models as desired, as RE can be long for example\n",
    "\n",
    "for model_name in models: \n",
    "    dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], \n",
    "                      'median_prob', input_offset=0.001)\n",
    "    x, y = dataset.prepare_no_split()\n",
    "    preds_bootstrap[model_name] = bootstrap(dict_models[model_name], x, y, repeat=repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing MEan and SE of errors\n",
    "\n",
    "dict_pred = {model_name: preds_bootstrap[model_name].mean(1) for model_name in preds_bootstrap}\n",
    "# dict_pred_natural = {model_name: 10**preds_bootstrap[model_name].mean(1) for model_name in preds_bootstrap}\n",
    "dict_se = {model_name: pred.std(1)/np.sqrt(repeat - np.isnan(pred).sum(1)) for model_name, pred in preds_bootstrap.items()}\n",
    "dict_se_natural = {model_name: 10**pred.std(1)/np.sqrt(repeat - np.isnan(pred).sum(1)) for model_name, pred in preds_bootstrap.items()}\n",
    "\n",
    "import_process = True\n",
    "if import_process:\n",
    "    dict_pred['process'] = np.log10(pd.read_csv('s3://jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/df_ww_cis_with_process_estimates_20210617.csv', parse_dates=['date']).set_index(['CIS20CD', 'date']).loc[dict_pred['xgb'].index]['process_based_estimate'])\n",
    "\n",
    "# Export of scores\n",
    "save = False\n",
    "if save:\n",
    "    bucket = \"s3://jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/cis_results\"\n",
    "    \n",
    "    for model_name in dict_pred:\n",
    "        dict_pred[model_name].to_csv(bucket+f'/predictions_{model_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12055d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing some metrics for one model\n",
    "model_name = 'xgb'\n",
    "\n",
    "# Log space\n",
    "# print('Log Space')\n",
    "# print(f'median relative error {np.abs((dict_pred[model_name]-y)/y).median()*100:.4f} %')\n",
    "# print(f'q95 relative error {np.quantile(np.abs((dict_pred[model_name]-y)/y), 0.95)*100:.4f}')\n",
    "print(f'mean absolute error {np.abs((dict_pred[model_name]-y)).mean():.4f}')\n",
    "print(f'median absolute error {np.abs((dict_pred[model_name]-y)).median():.4f}')\n",
    "print(f'q95 absolute error {np.quantile(np.abs((dict_pred[model_name]-y)), 0.95):.4f}')\n",
    "\n",
    "# Natural space\n",
    "print('\\nNatural space')\n",
    "print(f'median relative error {np.abs((10**dict_pred[model_name]-10**y)/10**y).median()*100:.4f}')\n",
    "print(f'q95 relative error {np.quantile(np.abs((10**dict_pred[model_name]-10**y)/10**y), 0.95)*100:.4f}')\n",
    "\n",
    "print(f'median absolute error {np.abs((10**dict_pred[model_name]-10**y)).median()*100:.4f}')\n",
    "print(f'q95 absolute error {np.quantile(np.abs((10**dict_pred[model_name]-10**y)), 0.95)*100:.4f}')\n",
    "\n",
    "plt.hist((10**dict_pred[model_name]-10**y)/10**y*100, 75, range=(-100, 200))\n",
    "plt.xlabel('relative error (%)')\n",
    "plt.show()\n",
    "\n",
    "plt.hist((10**dict_pred[model_name]-10**y), 50, range=(-3,3))\n",
    "plt.xlabel('signed error (% infected)')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1789a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot comparison for different models\n",
    "\n",
    "names = [ 'process', 're', 'xgb']\n",
    "per_subregion = True\n",
    "\n",
    "dict_err = {name: np.abs((dict_pred[name] -y)) if not per_subregion else np.abs((dict_pred[name] -y)).groupby('CIS20CD').mean() for name in names}\n",
    "plt.boxplot([dict_err[name] for name in names], \n",
    "           )\n",
    "plt.xticks(range(1, 1+len(names)), labels=[model_labels[name] for name in names])\n",
    "plt.ylabel(f\"MAE {'per subregion' if per_subregion else ''}\\n (Log10 % infected)\")\n",
    "plt.show()\n",
    "\n",
    "dict_err = {name: np.abs((10**dict_pred[name] - 10**y)) if not per_subregion else np.abs((10**dict_pred[name] - 10**y)).groupby('CIS20CD').mean() for name in names}\n",
    "plt.boxplot([dict_err[name] for name in names], \n",
    "           )\n",
    "plt.xticks(range(1, 1+len(names)), labels=[model_labels[name] for name in names])\n",
    "plt.ylabel(f\"MAE {'per subregion' if per_subregion else ''}\\n (% infected)\", fontsize=14)\n",
    "plt.yscale('log')\n",
    "plt.yticks(fontsize=12)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of period sample\n",
    "# dict_pred_test = dict()\n",
    "# start_date_test='2021-01-15'\n",
    "\n",
    "# for name, model in dict_models.items():\n",
    "#     dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[name], \n",
    "#                   'median_prob', input_offset=0.001)\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = dataset.temporal_split(start_date_test=start_date_test)\n",
    "    \n",
    "#     model.fit(x_train, y_train)\n",
    "#     dict_pred_test[name] = model.predict(x_test)\n",
    "#     print(name, f'mae = {compute_mae(y_test, dict_pred_test[name]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation on whole dataset, instead of boostrap\n",
    "# from wastewater.ml_utils import predict_kfold\n",
    "# dict_pred = dict()\n",
    "# for name, model in dict_models.items():\n",
    "#     dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[name], \n",
    "#                       'median_prob', input_offset=0.001)\n",
    "#     x, y = dataset.prepare_no_split()\n",
    "#     dict_pred[name] = predict_kfold(model, x, y, 5)\n",
    "#     print(name, f'mae = {compute_mae(y, dict_pred[name]):.4f}', f'mae_natural = {compute_mae_natural(y, dict_pred[name]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905189ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wastewater.ml_utils import plot_conditional_pred\n",
    "\n",
    "for name in dict_models:\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    plot_conditional_pred(dataset.y, dict_pred[name], title=model_labels[name], ax=ax)\n",
    "    ax.set_ylabel(f'Predictions (log10)', fontsize=14)\n",
    "    ax.set_xlabel('True values (Log10)', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b800b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Error as a function of time\n",
    "\n",
    "# f, ax = plt.subplots(2, figsize=(12,12), sharex=True)\n",
    "# ax[1].plot(y.groupby('date').mean().rolling(7).mean(), color='black', label='data')\n",
    "\n",
    "\n",
    "# for model_name in ['re', 'xgb']:\n",
    "#     mae_time = (dict_pred[model_name]-dataset.y).groupby('date').agg(lambda x: np.abs(x).mean()).rolling(7).mean()\n",
    "    \n",
    "#     ax[0].plot(mae_time, '-o', label=model_labels[model_name])\n",
    "#     ax[0].set_ylabel('Mean Absolute Error', fontsize=14)\n",
    "    \n",
    "    \n",
    "#     pred_time = dict_pred[model_name].groupby('date').mean().rolling(7).mean()\n",
    "#     rmse_time = (dict_pred[model_name]-dataset.y).groupby('date').agg(lambda x: (x**2).mean()).rolling(7).mean()\n",
    "#     ax[1].plot(pred_time, label=f'preds ({model_labels[model_name]})')\n",
    "#     ax[1].fill_between(pred_time.index,\n",
    "#                        pred_time - 2 * rmse_time,\n",
    "#                        pred_time + 2 * rmse_time,\n",
    "#                        alpha=0.5, label=f'$2 \\sigma \\simeq 2*RMSE $ ({model_labels[model_name]})'\n",
    "#                       )\n",
    "    \n",
    "#     # Show Interventions :)\n",
    "\n",
    "#     pass\n",
    "# ax[0].legend()\n",
    "# ax[1].legend()\n",
    "# ax[1].set_ylabel('Log10 CIS pos. rates', fontsize=14)\n",
    "# ax[1].set_ylim(-1.,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a819ed",
   "metadata": {},
   "source": [
    "##### National average of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c68a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "model_name = 'xgb'\n",
    "z = dict_pred[model_name].groupby('date').mean()\n",
    "z_se = dict_se[model_name].groupby('date').mean()\n",
    "\n",
    "z_cis = df[['CIS20CD', 'date', 'median_prob', \"ll\", 'ul']].groupby('date').mean().rolling('7D').mean()\n",
    "\n",
    "\n",
    "plt.plot(y.groupby('date').mean().rolling('7D').mean(), color='black', label='data')\n",
    "plt.fill_between(z_cis.index, \n",
    "                 np.log10(z_cis.ll), \n",
    "                 np.log10(z_cis.ul), alpha=0.3, color='black', label='CIS 95% CI')\n",
    "plt.plot(z.rolling('7D').mean(),\n",
    "         color='blue', label=f'mean prediction ({model_labels[model_name]})')\n",
    "plt.errorbar(z.index, \n",
    "             z.rolling('7D').mean(), \n",
    "             2*z_se.rolling('7D').mean(),\n",
    "             color='blue', alpha=0.7, label='Boostrap 95% CI')\n",
    "plt.ylabel('CIS pos. rates (log10 % infected)', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Natural space\n",
    "plt.figure(figsize=(12, 5))\n",
    "model_name = 'xgb'\n",
    "z = (10**dict_pred[model_name]).groupby('date').mean()\n",
    "z_se_natural = dict_se_natural[model_name].groupby('date').mean()\n",
    "\n",
    "plt.plot((10**y).groupby('date').mean().rolling('7D').mean(), color='black', label='data')\n",
    "plt.fill_between(z_cis.index, \n",
    "                 z_cis.ll, \n",
    "                 z_cis.ul, alpha=0.3, color='black', label='CIS 95% CI')\n",
    "plt.plot(z.rolling('7D').mean(),\n",
    "         color='blue', label=f'mean prediction ({model_labels[model_name]})')\n",
    "plt.errorbar(z.index, \n",
    "             z.rolling('7D').mean(), \n",
    "             2*z_se.rolling('7D').mean(),\n",
    "             color='blue', alpha=0.7, label='Boostrap 95% CI')\n",
    "plt.ylabel('CIS pos. rates (% infected)', fontsize=14)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762936f8",
   "metadata": {},
   "source": [
    "##### Subregional average of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69476c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xgb\"\n",
    "\n",
    "include_ww = True\n",
    "\n",
    "region_names = ww.read_dataset('LOOKUP_REGISTER_ONS_GEO_CODE').set_index('region_code')[['region_name']].dropna().drop_duplicates()\n",
    "region_names = region_names.reset_index().rename(columns={'region_code': 'RGN19CD'})\n",
    "\n",
    "regions = df_cis[['CIS20CD', 'RGN19CD']].drop_duplicates().merge(region_names)\n",
    "z = dataset.inverse_transform_y(dict_pred[model_name]).reset_index().merge(regions)\n",
    "z = z.rename(columns={0: 'pred'}).merge(df[['sars_cov2_gc_l_mean', 'catch_cis_population', 'CIS20CD', 'date', 'median_prob', \"ll\", 'ul']])\n",
    "\n",
    "\n",
    "se_natural = (dataset.inverse_transform_y(preds_bootstrap[model_name]).std(1) \n",
    "              / np.sqrt(repeat - np.isnan(preds_bootstrap[model_name]).sum(1)))\n",
    "z = z.merge(se_natural.reset_index().rename(columns={0: 'se'}))\n",
    "\n",
    "\n",
    "regions = ['North West','Yorkshire and The Humber',  'North East', \n",
    "           'West Midlands', 'East Midlands', 'East of England', \n",
    "           'South West', 'London', 'South East']\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(14,9), sharex=True, sharey=True)\n",
    "\n",
    "for i, (region, ax) in enumerate(zip(regions, axes.flatten())):\n",
    "    group = z[z.region_name == region]\n",
    "    def fn(x):\n",
    "        x = x[~np.isnan(x)]\n",
    "        if not len(x):\n",
    "            return np.nan\n",
    "        weights = group.loc[x.index, 'catch_cis_population']\n",
    "        if np.sum(weights) == 0.:\n",
    "            weights = np.ones(x.shape)\n",
    "        return np.average(x, weights=weights)\n",
    "#     fn = lambda x: x.mean()\n",
    "\n",
    "    group = group.groupby('date').agg(fn)\n",
    "\n",
    "    ax.plot(group.median_prob.rolling('7D').mean(), color='black', alpha=0.8, label='CIS median proba')\n",
    "    ax.fill_between(group.rolling('7D').mean().index, \n",
    "                    group.rolling('7D').mean().ll, \n",
    "                    group.rolling('7D').mean().ul, alpha=0.3, color='black', label='CIS 95% CI')\n",
    "    \n",
    "    ax.plot(group.pred.rolling('7D').mean(), color='blue', lw=2, alpha=0.8, label=f'predictions')\n",
    "#     ax.plot(group.d.rolling('7D').mean(), color='blue', lw=2, alpha=0.8, label=f'predictions ({model_labels[model_name]})')\n",
    "    ax.errorbar(group.pred.rolling('7D').mean().index, \n",
    "                group.pred.rolling('7D').mean(),\n",
    "                2*group.se.rolling('7D').mean(),\n",
    "                color='blue', fmt='none', alpha=0.5, label=f'boostrap 95% CI')\n",
    "    \n",
    "    if i%3==0:\n",
    "        ax.set_ylabel('Prevalence (%)', fontsize=13)\n",
    "    ax.set_title(region, fontsize=15)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "    if  region == \"South West\":\n",
    "#         ax.legend(loc='upper left', fontsize=11)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(np.array(handles)[[0, 2, 1, 3]], np.array(labels)[[0, 2, 1, 3]], loc='upper left', fontsize=12)\n",
    "        \n",
    "    if include_ww:\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(group.sars_cov2_gc_l_mean.rolling('7D').mean(), color='orange', lw=1.1, alpha=0.8, label=f'Wastewater data')\n",
    "        \n",
    "        if i%3==2:\n",
    "            ax2.set_ylabel('SARS-CoV-2 (gc/L)', fontsize=13)\n",
    "        else:\n",
    "            ax2.set_yticks([])\n",
    "        if  region == \"South East\":\n",
    "            ax2.legend(loc='upper right', fontsize=12)\n",
    "    ax2.set_ylim(-10000, 400000)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence of errors with viral load\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for name in ['lr', 're', 'xgb']:\n",
    "    mean_list = []\n",
    "    se_list = []\n",
    "#     plt.scatter(x['sars_cov2_gc_l_mean'], np.abs(dict_pred[name] - y), s=3)\n",
    "\n",
    "    _, bins = np.histogram(x['sars_cov2_gc_l_mean'], bins=7)\n",
    "    for i in range(len(bins)-1):\n",
    "        z = (np.abs(dict_pred[name] - y))[(x['sars_cov2_gc_l_mean']>=bins[i]) & (x['sars_cov2_gc_l_mean']<=bins[i+1])]\n",
    "        mean_list.append(z.mean())\n",
    "        se_list.append(z.std()/np.sqrt(len(z)))\n",
    "    plt.scatter([(bins[i] + bins[i+1])/2 for i in range(len(bins)-1)], \n",
    "                mean_list)\n",
    "    plt.errorbar([(bins[i] + bins[i+1])/2 for i in range(len(bins)-1)], \n",
    "                 mean_list, 2*np.array(se_list), label=model_labels[name])\n",
    "plt.xlabel('SARS-CoV2 Concentration (gc/L)', fontsize=14)\n",
    "plt.ylabel('Mean Absolute Error (Log10)', fontsize=14)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute sites error\n",
    "save = False\n",
    "agg = np.median\n",
    "\n",
    "# Collect errors per site\n",
    "list_mae = []\n",
    "list_mae_natural = []\n",
    "\n",
    "save = False\n",
    "for model_name in dict_pred:\n",
    "    list_mae.append((y - dict_pred[model_name]).groupby('CIS20CD').agg(lambda x: agg(np.abs(x))))\n",
    "    list_mae[-1].name = model_name\n",
    "    list_mae_natural.append((10**y - 10**dict_pred[model_name]).groupby('CIS20CD').agg(lambda x:  agg(np.abs(x))))\n",
    "    list_mae_natural[-1].name = model_name\n",
    "mae_per_site = pd.concat(list_mae, 1)\n",
    "mae_natural_per_site = pd.concat(list_mae_natural, 1)\n",
    "\n",
    "if save:\n",
    "    mae_per_site.to_csv(ww.output_dir + '/cis_mae_per_site.csv')\n",
    "# mae_per_site.corr(), mae_per_site.mean(), len(mae_per_site)\n",
    "\n",
    "\n",
    "# histograms of site errors\n",
    "# for col in ['process', 're', 'xgb']:\n",
    "#     plt.hist(mae_per_site[col], label=model_labels[col],\n",
    "#               alpha=0.5, range=(0, mae_per_site.max().max()), bins=30)\n",
    "# plt.xlabel('MAE [log10(%)]', fontsize=15)\n",
    "# plt.legend()\n",
    "\n",
    "# for col in ['process', 're', 'xgb']:\n",
    "#     plt.hist(mae_natural_per_site[col], label=model_labels[col], \n",
    "#              alpha=0.5, range=(0, mae_natural_per_site.max().max()), bins=30)\n",
    "# plt.xlabel('Mean Absolute Error (% infected)', fontsize=15)\n",
    "# plt.legend() \n",
    "\n",
    "# for model_name in ['re', 'xgb']:\n",
    "#     plt.hist((10**dict_pred[model_name]-10**y)/10**y,label=model_labels[model_name], \n",
    "#     alpha=0.5, range=(-3, 3), bins=50)\n",
    "# plt.xlabel('Error [% infected]', fontsize=15)\n",
    "# plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c34cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for each subregion\n",
    "f, ax = plt.subplots(figsize=(13,6))\n",
    "model_name = 're'\n",
    "mae = np.abs(dict_pred[model_name]-y)\n",
    "sorted_index = mae.groupby('CIS20CD').median().sort_values(ascending=False).index\n",
    "\n",
    "pd.DataFrame(mae.unstack(0)[sorted_index]).boxplot(ax=ax)\n",
    "plt.xticks(rotation=45, fontsize=5)\n",
    "plt.xlabel('CIS subregions', fontsize=16)\n",
    "plt.ylabel('Mean Absolute Error', fontsize=16)\n",
    "plt.title(f'{model_labels[model_name]}', fontsize=17)\n",
    "plt.ylim(0, 1)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e2e4a",
   "metadata": {},
   "source": [
    "# Var importance and coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292a250",
   "metadata": {},
   "source": [
    "##### XGB variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3efa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables['xgb'], 'median_prob', \n",
    "                              input_offset=0.001)\n",
    "x, y = dataset.prepare_no_split()\n",
    "dict_models['xgb'].fit(x, y)\n",
    "xgb_importance = pd.Series(dict_models['xgb'].feature_importances_, \n",
    "                           index=dataset.input_variables).sort_values(ascending=False)\n",
    "\n",
    "plt.bar(xgb_importance.index, xgb_importance)\n",
    "plt.xticks(rotation=45, horizontalalignment=\"right\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc7cc4",
   "metadata": {},
   "source": [
    "##### Coefficients from RE/RI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models[model_name].slope_vars = model_variables['re']\n",
    "model_variables['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fixed coef only\n",
    "# df_coefs = pd.DataFrame(columns=dataset.input_variables)\n",
    "# for name in ['re', 'ri']:\n",
    "#     variables = model_variables[name]\n",
    "#     dict_models[name].fit(x[model_variables['xgb']], y)\n",
    "#     try:\n",
    "#         df_coefs = df_coefs.append(pd.Series(dict_models[name].coef_, name=name, index=variables))\n",
    "#     except AttributeError:\n",
    "#         pass\n",
    "#     except KeyError:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54077662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in df_coefs.index:\n",
    "#     df_coefs_t = df_coefs.T.sort_values(name, ascending=False)\n",
    "#     plt.bar(df_coefs_t.index, df_coefs_t[name], alpha=0.5)\n",
    "#     plt.xticks(rotation=45, horizontalalignment=\"right\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bea604",
   "metadata": {},
   "source": [
    "##### Random effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 're'\n",
    "\n",
    "dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], \n",
    "                      'median_prob', input_offset=0.001)\n",
    "x, y = dataset.prepare_no_split()\n",
    "\n",
    "dict_models[model_name].fit(x[model_variables[model_name]], y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c93ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {('Intercept' if var=='Group' else var): [dict_models[model].results_.random_effects[cis][var] \n",
    "           for cis in dict_models[model].results_.random_effects] for var in ['Group'] + dataset.input_variables}\n",
    "variable_labels['Group'] = 'intercept'\n",
    "\n",
    "data_boxplot = [(np.array([dict_models[model_name].results_.fe_params[k]])\n",
    "                + np.array(v)) #/dataset.scaler.scale_[i]\n",
    "                for i, (k,v) in enumerate(d.items())] \n",
    "\n",
    "# whether to convert back to original units\n",
    "# data_boxplot = (data_boxplot * dataset.scaler.scale_[:,np.newaxis])\n",
    "data_boxplot = np.array(data_boxplot)\n",
    "plt.boxplot(data_boxplot.T)\n",
    "\n",
    "for i in range(len(data_boxplot)):\n",
    "    y = data_boxplot[i]\n",
    "    x = np.random.normal(1+i, 0.04, size=len(y))\n",
    "    plt.plot(x, y, 'r.', alpha=0.2)\n",
    "plt.xticks(range(1, 1+len(data_boxplot)), \n",
    "           ['Intercept']+[variable_labels[k] for k in dataset.input_variables], \n",
    "           rotation=45, horizontalalignment=\"right\")\n",
    "# plt.hlines(0, 1,  1+len(data_boxplot), color='black', linestyle='')\n",
    "plt.grid()\n",
    "plt.ylabel('Random Effect coefficients', fontsize=14)\n",
    "plt.xlabel('Input variables', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(data_boxplot.T, columns=d.keys())\n",
    "df3['CIS20CD'] = [cis for cis in dict_models[model].results_.random_effects]\n",
    "df3 = df3.merge(df_cis[['CIS20CD','RGN19CD']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261df06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(d.keys())[1:]:\n",
    "    plt.figure(figsize=(9,7))\n",
    "    for region, group in df3.groupby('RGN19CD'):\n",
    "        plt.scatter(group.Intercept, group[col], label=region_names.set_index('RGN19CD').loc[region].iloc[0], s=50)\n",
    "        plt.title(variable_labels[col], fontsize=17)\n",
    "        plt.ylabel(f'Subregion coefficient', fontsize=15)\n",
    "        plt.xlabel('Subegion Intercepts', fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feda37d",
   "metadata": {},
   "source": [
    "##### Partial dependence plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# This function comes from here: https://github.com/dmlc/xgboost/issues/2035\n",
    "def partial_dependency(model, X, features, selected_feature):\n",
    "    # The model could be an XGBoost sklearn fitted instance (or anything else with a \n",
    "    # predict method)\n",
    "    X_temp = X.copy()\n",
    "    # Works only for numerical features. Find something else for categorical features.\n",
    "    grid = np.linspace(np.percentile(X_temp.loc[:, selected_feature], 0.1), \n",
    "                       np.percentile(X_temp.loc[:, selected_feature], 99.5), \n",
    "                       50)\n",
    "    y_pred = np.zeros(len(grid))\n",
    "    \n",
    "    for i, val in enumerate(grid):\n",
    "        X_temp.loc[:, selected_feature] = val\n",
    "        y_pred[i] = model.predict(X_temp.loc[:, features]).mean()\n",
    "    \n",
    "    return grid, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "model_name = \"xgb\"\n",
    "\n",
    "dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], \n",
    "                      'median_prob', input_offset=0.001)\n",
    "x, y = dataset.prepare_no_split()\n",
    "model = dict_models[model_name]\n",
    "model.fit(x, y)\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(15,15))\n",
    "variables_to_plot = ['sars_cov2_gc_l_mean', 'suspended_solids_mg_l', 'ammonia_mg_l',\n",
    "                     'ophosph_mg_l', 'sample_ph_pre_ansis', 'control_gc_l_mean','compo_frac',  'sars_below_loq',\n",
    "                     'reception_delay', 'catchment_population_ons_mid_2019',\n",
    "                     'catchment_area', 'catch_in_cis_prop'] #, 'catch_cis_population']\n",
    "\n",
    "f, axes = plt.subplots(3, 4, figsize=(16,12), sharey=True)\n",
    "\n",
    "for ax, selected_feature in zip(axes.flatten(), variables_to_plot):\n",
    "    try:\n",
    "        grid, out = partial_dependency(model, x, x.columns, selected_feature)\n",
    "        ax.plot(grid, out)\n",
    "        ax.set_xlabel(variable_labels[selected_feature], fontsize=15)\n",
    "        ax.set_ylabel('CIS positivity rates (Log10 %)', fontsize=14)\n",
    "    except KeyError:\n",
    "        continue\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690c9df",
   "metadata": {},
   "source": [
    "# Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f450ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wastewater.ml_utils import predict_kfold, bootstrap\n",
    "\n",
    "shifts = range(-10, 20, 1)\n",
    "repeat= 50\n",
    "\n",
    "mae_list = {name: [] for name in dict_models}\n",
    "mae_sem_list ={name: [] for name in dict_models}\n",
    "mae_natural_list = {name: [] for name in dict_models}\n",
    "mae_natural_sem_list = {name: [] for name in dict_models}\n",
    "\n",
    "models = ['lr', 'xgb']\n",
    "\n",
    "df_ww_2 = df_ww.copy()\n",
    "\n",
    "# Test of dates consistency\n",
    "assert df_cis_interpolated.date.min() >= df_ww_2.date.min() + datetime.timedelta(shifts[-1])\n",
    "assert df_cis_interpolated.date.max() <= df_ww_2.date.max() + datetime.timedelta(shifts[0])\n",
    "\n",
    "for model_name in models:\n",
    "    for shift in shifts:\n",
    "        df_ww_shifted = df_ww.copy()\n",
    "        df_ww_shifted['date'] += datetime.timedelta(shift)\n",
    "        df = df_ww_shifted.merge(df_cis_interpolated, how='inner').sort_values(['CIS20CD', 'date'])  # change for left\n",
    "        df = df.dropna(subset=['CIS20CD', 'date'])\n",
    "#         df = df[df.date > datetime.datetime(2020,8,1)]\n",
    "        # Check on the compatibility of dates !\n",
    "\n",
    "\n",
    "        print(shift, len(df))\n",
    "\n",
    "        dataset = Dataset(df.set_index(['CIS20CD', 'date']), \n",
    "                          model_variables[model_name], \n",
    "                          'median_prob', \n",
    "                          input_offset=0.001\n",
    "                         )\n",
    "        x, y = dataset.prepare_no_split()\n",
    "\n",
    "        model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "        pred = predict_kfold(model, x, y)\n",
    "        bootstrap_pred = bootstrap(dict_models[model_name], x, y, repeat=repeat)\n",
    "        n_preds = repeat - np.isnan(bootstrap_pred).sum(1)\n",
    "\n",
    "\n",
    "        mae_list[model_name].append(compute_mae(y, bootstrap_pred.mean(1)))\n",
    "        mae_sem_list[model_name].append(np.abs(bootstrap_pred - y.values[:,np.newaxis]).mean(0).std() / np.sqrt(repeat))        \n",
    "        \n",
    "        mae_natural_list[model_name].append( np.abs(10**y - 10**bootstrap_pred.mean(1)).mean())\n",
    "        mae_natural_sem_list[model_name].append(np.abs(10**bootstrap_pred - 10**y.values[:,np.newaxis]).mean(0).std() / np.sqrt(repeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "\n",
    "for model_name in models:\n",
    "    plt.figure()\n",
    "    plt.title(model_labels[model_name], fontsize=15)\n",
    "    plt.plot(shifts, pd.Series(mae_list[model_name]).rolling(window, center=True, min_periods=1).mean(), \n",
    "             '-o', markersize=6, color='blue', label=\"mean\")\n",
    "    plt.errorbar(shifts, pd.Series(mae_list[model_name]).rolling(window, center=True, min_periods=1).mean(), \n",
    "                 2 * np.array(mae_sem_list[model_name]), \n",
    "                 markersize=5,  color='blue', label='95% CI')\n",
    "    plt.ylabel('Mean Absolute Error (log10 space)', fontsize=14)\n",
    "    plt.xlabel('WW shift (days)', fontsize=14)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in models:\n",
    "    plt.figure()\n",
    "    plt.title(model_labels[model_name], fontsize=15)\n",
    "    plt.plot(shifts, pd.Series(mae_natural_list[model_name]).rolling(window, center=True, min_periods=1).mean(), \n",
    "             '-o', markersize=6, color='blue', label=\"mean\")\n",
    "    plt.errorbar(shifts, pd.Series(mae_natural_list[model_name]).rolling(window, center=True, min_periods=1).mean(), \n",
    "                 2 * np.array(mae_sem_list[model_name]), \n",
    "                 markersize=5,  color='blue', label='95% CI')\n",
    "    plt.ylabel('Mean Absolute Error (natural)', fontsize=14)\n",
    "    plt.xlabel('WW shift (days)', fontsize=14)\n",
    "    plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"s3://jbc-staging-data-wip/jbc-wip/01. Data/01. Raw/Waste Water/ww_users/mario/cis_results\"\n",
    "pd.Series(mae_list[model_name]).to_csv(bucket+f\"/cis_shifts_mae_{model_name}.csv\", index=False)\n",
    "pd.Series(mae_sem_list[model_name]).to_csv(bucket+f\"/cis_shifts_mae_sem_{model_name}.csv\", index=False)\n",
    "pd.Series(mae_natural_list[model_name]).to_csv(bucket+f\"/cis_shifts_mae_natural_{model_name}.csv\", index=False)\n",
    "pd.Series(mae_natural_sem_list[model_name]).to_csv(bucket+f\"/cis_shifts_mae_sem_natural_{model_name}.csv\", index=False)\n",
    "pd.Series(shifts).to_csv(bucket+f\"/cis_shifts_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315296cc",
   "metadata": {},
   "source": [
    "## Ablation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an evaluation strategy: random samples or latest dates?\n",
    "evaluation = lambda dataset: dataset.random_split(0.2)  # Random samples evaluation\n",
    "evaluation = lambda dataset: dataset.temporal_split(start_date_test='2021-02-01')  # out of time range evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the start week\n",
    "max_train_date = df_cis_interpolated.date.max()\n",
    "min_date_0 = df_cis_interpolated.date.min()\n",
    "\n",
    "n_weeks = ((max_train_date - df_cis_interpolated.date.min())/7).days\n",
    "\n",
    "mae = {name: [] for name in dict_models}\n",
    "\n",
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    for week in range(int(n_weeks*0.75)):        \n",
    "        min_date = min_date_0 + datetime.timedelta(week*7)\n",
    "        \n",
    "        dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], 'median_prob', \n",
    "                          input_offset=0.001)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = evaluation(dataset)\n",
    "        x_train_temp = x_train[(x_train.reset_index(1).date>= min_date).values]\n",
    "        y_train_temp = y_train[(y_train.reset_index(1).date>= min_date).values]\n",
    "        \n",
    "        model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "        model.fit(x_train_temp, y_train_temp)\n",
    "\n",
    "        pred_test = model.predict(x_test)\n",
    "\n",
    "        mae[model_name].append(compute_mae(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in mae:\n",
    "    plt.plot(mae[model_name], '-o', label=model_labels[model_name])\n",
    "plt.ylabel('Mean Absolute Error', fontsize=14)\n",
    "plt.xlabel('start week', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreasing the end week\n",
    "max_date_0 = df_cis_interpolated.date.max()\n",
    "\n",
    "n_weeks = ((max_train_date - df_cis_interpolated.date.min())/7).days\n",
    "\n",
    "mae = {name: [] for name in dict_models}\n",
    "\n",
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    for week in range(int(n_weeks*0.75)):        \n",
    "        max_date = max_date_0 - datetime.timedelta(week*7)\n",
    "        \n",
    "        dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], 'median_prob', \n",
    "                          input_offset=0.001)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = evaluation(dataset)\n",
    "        x_train_temp = x_train[(x_train.reset_index(1).date<= max_date).values]\n",
    "        y_train_temp = y_train[(y_train.reset_index(1).date<= max_date).values]\n",
    "        \n",
    "        model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "        model.fit(x_train_temp, y_train_temp)\n",
    "\n",
    "        pred_test = model.predict(x_test)\n",
    "\n",
    "        mae[model_name].append(compute_mae(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e31da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in mae:\n",
    "    plt.plot(mae[model_name], '-o', label=model_labels[model_name])\n",
    "plt.ylabel('Mean Absolute Error', fontsize=14)\n",
    "plt.xlabel('Removed weeks (at the end)', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b388696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly exluding training samples\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_date_0 = df_cis_interpolated.date.max()\n",
    "\n",
    "n_weeks = ((max_train_date - df_cis_interpolated.date.min())/7).days\n",
    "\n",
    "mae = {name: [] for name in dict_models}\n",
    "\n",
    "test_sizes = np.linspace(0.1, 0.9, 10)\n",
    "\n",
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    for test_size in test_sizes:       \n",
    "        max_date = max_date_0 - datetime.timedelta(week*7)\n",
    "        \n",
    "        dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], 'median_prob', \n",
    "                          input_offset=0.001)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = evaluation(dataset)\n",
    "        \n",
    "        x_train_temp, _, y_train_temp, _ = train_test_split(x_train, y_train, random_state=0, test_size=test_size)\n",
    "        \n",
    "        model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "        model.fit(x_train_temp, y_train_temp)\n",
    "\n",
    "        pred_test = model.predict(x_test)\n",
    "\n",
    "        mae[model_name].append(compute_mae(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    plt.plot(test_sizes*100, mae[model_name], '-o', label=model_labels[model_name])\n",
    "plt.ylabel('Mean Absolute Error', fontsize=14)\n",
    "plt.xlabel('removed train samples (%)', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly exluding training sites\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_date_0 = df_cis_interpolated.date.max()\n",
    "\n",
    "n_weeks = ((max_train_date - df_cis_interpolated.date.min())/7).days\n",
    "\n",
    "mae = {name: [] for name in dict_models}\n",
    "\n",
    "n_removed_sites = np.arange(0, int(len(df.CIS20CD.unique())*0.75), 5)\n",
    "\n",
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    for i in n_removed_sites:\n",
    "            subregions = np.random.choice(df.CIS20CD.unique(), size=len(df.CIS20CD.unique()) - i, replace=False)\n",
    "            dataset = Dataset(df.set_index(['CIS20CD', 'date']), model_variables[model_name], 'median_prob', \n",
    "                              input_offset=0.001)\n",
    "            x_train, x_test, y_train, y_test = evaluation(dataset)\n",
    "\n",
    "            x_train_temp = x_train.loc[subregions]\n",
    "            y_train_temp = y_train.loc[subregions]\n",
    "\n",
    "            model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "            model.fit(x_train_temp, y_train_temp)\n",
    "\n",
    "            pred_test = model.predict(x_test)\n",
    "\n",
    "            mae[model_name].append(compute_mae(y_test, pred_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['xgb', \"lr\", 're']:\n",
    "    plt.plot(n_removed_sites/len(df.CIS20CD.unique())*100, mae[model_name], '-o', label=model_labels[model_name])\n",
    "plt.ylabel('Mean Absolute Error', fontsize=14)\n",
    "plt.xlabel('removed subregions (%)', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e376d27",
   "metadata": {},
   "source": [
    "# CIS stochastic sampling\n",
    "\n",
    "- CIS is skewed, Q975 alwawys further from median than Q025\n",
    "- pos rates always positive by definition\n",
    "\n",
    "--> log-normal sensible choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((df_cis.ul - df_cis.median_prob) / (df_cis.median_prob - df_cis.ll), 50)\n",
    "plt.title('Ratio of (Q975 - Median)/(Median - Q025)', fontsize=17)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lognormal_params_from_cis(df_cis):\n",
    "    # mu \n",
    "    mu = np.log(df_cis.median_prob)\n",
    "\n",
    "    # sigma\n",
    "    p = 0.025\n",
    "    sigma = (1  / np.sqrt(2)) * (np.log(df_cis.ll) - mu) / scipy.special.erfinv(2*p-1)\n",
    "\n",
    "    return mu, sigma\n",
    "\n",
    "def sample_from_cis(df_cis, size=None):\n",
    "    mu, sigma = compute_lognormal_params_from_cis(df_cis)\n",
    "    return np.random.lognormal(mu, sigma, size=size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278578f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = compute_lognormal_params_from_cis(df_cis)\n",
    "\n",
    "q975 = np.exp(mu + np.sqrt(2)*sigma*scipy.special.erfinv(2*0.975-1))\n",
    "\n",
    "plt.hist((q975 - df_cis.ul)/df_cis.ul*100, 50)\n",
    "plt.title('relative error in q975',fontsize= 17)\n",
    "plt.xlabel('%', fontsize=15)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf555db",
   "metadata": {},
   "source": [
    "#### This confirms that lognormal is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73854116",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_from_cis(df_cis), 100)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at distribution\n",
    "n_samples=5000\n",
    "i = 5\n",
    "h, b, _ = plt.hist([sample_from_cis(df_cis.iloc[i]) for _ in range(n_samples)], 50)\n",
    "plt.vlines(df_cis.median_prob[i], 0, np.max(h), color='green', label='median', lw=5)\n",
    "plt.vlines(df_cis.ll[i], 0, np.max(h), color='red', label='LL')\n",
    "plt.vlines(df_cis.ul[i], 0, np.max(h), color='purple', label='UL')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933187cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_sampled_from_cis(df_cis_interpolated, df_ww_agg, *args, **kwargs):\n",
    "    df_cis_interpolated_temp = df_cis_interpolated.copy()\n",
    "    df_cis_interpolated_temp['sample'] = np.nan\n",
    "    \n",
    "    df_cis_interpolated_temp['sample'] = sample_from_cis(df_cis_interpolated)\n",
    "    df_temp = df_ww_agg.merge(df_cis_interpolated_temp, how='inner').sort_values(['CIS20CD', 'date'])  # change for left\n",
    "    df_temp = df_temp.dropna(subset=['CIS20CD', 'date'])\n",
    "    return Dataset(df_temp.set_index(['CIS20CD', 'date']), *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e60652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model for 10 samples\n",
    "n_samples = 10\n",
    "\n",
    "samples = {name: [] for name in dict_models}\n",
    "preds = {name: [] for name in dict_models}\n",
    "\n",
    "for model_name in ['xgb', 're']:\n",
    "    for i in range(n_samples):\n",
    "        dataset = dataset_sampled_from_cis(df_cis_interpolated, df_ww_agg, \n",
    "                                           model_variables[model_name], \n",
    "                                           'sample', \n",
    "                                           input_offset=0.001\n",
    "                                          )\n",
    "        x, y = dataset.prepare_no_split()\n",
    "\n",
    "        model = sklearn.base.clone(dict_models[model_name])\n",
    "\n",
    "        samples[model_name].append(y)\n",
    "        preds[model_name].append(predict_kfold(model, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['xgb', 're']:\n",
    "    mean_samples =  np.array(samples[model_name]).mean(0)\n",
    "    sem_samples = np.array(samples[model_name]).std(0) / np.sqrt(n_samples)\n",
    "\n",
    "    mean_preds =  np.array(preds[model_name]).mean(0)\n",
    "    sem_preds = np.array(preds[model_name]).std(0) / np.sqrt(n_samples)\n",
    "\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.errorbar(y, mean_preds, xerr=sem_samples, yerr=2*sem_preds,fmt='o', markersize=1, label='$2\\sigma_{mean}$', alpha=0.7)\n",
    "    plt.ylabel('Predicted Log CIS positivity rate', fontsize=15)\n",
    "    plt.xlabel('Sampled Log CIS positivity rate', fontsize=15)\n",
    "    plt.title(f'Predictions from {model_labels[model_name]}', fontsize=16)\n",
    "    plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red')\n",
    "    plt.ylim(-1.5, 1.)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sem_preds, 50)\n",
    "plt.title(f'Std. err. mean preds. when sampling target according to CIS distribution ({n_samples} repeats)', fontsize=14)\n",
    "plt.xlabel('$\\sigma_{CIS}$', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([np.nanmean(np.abs(np.array(preds[model_name]) - np.array(samples[model_name])), 1) \n",
    "             for model_name in ['re', 'xgb']])\n",
    "plt.ylabel('Mean Absolute Error', fontsize=15)\n",
    "plt.xticks(range(1, 3), [model_labels[name] for name in ['re', 'xgb']], rotation=0, fontsize=15)\n",
    "plt.title('Prediction-error when sampling in CIS Conf. Int.', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99d0c3",
   "metadata": {},
   "source": [
    "# Quantile prediction from gradient boosted\n",
    "- use example here: https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html\n",
    "- potential issue when using xgb so using only classic gradient boosted algo below :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c609b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# # Quantile loss XGB\n",
    "# alpha = 0.05\n",
    "# gbm = GradientBoostingRegressor()\n",
    "# gbm_lower = GradientBoostingRegressor(loss=\"quantile\", alpha=alpha)\n",
    "# gbm_upper = GradientBoostingRegressor(loss=\"quantile\", alpha=1-alpha)\n",
    "\n",
    "# pred = predict_kfold(gbm, x, y)\n",
    "# pred_lower = predict_kfold(gbm_lower, x, y)\n",
    "# pred_upper = predict_kfold(gbm_upper, x, y)\n",
    "\n",
    "# assert (pred_lower < pred).mean() and (pred_upper > pred)\n",
    "\n",
    "# plt.figure(figsize=(11, 5))\n",
    "\n",
    "# plt.scatter(pred, pred_upper, s=1, label=f'lower quantile ($\\\\alpha=${alpha})')\n",
    "# plt.scatter(pred, pred_lower, s=1, label=f'upper quantile ($\\\\alpha=${1-alpha})')\n",
    "# plt.plot([pred.min(), pred.max()], [pred.min(), pred.max()], color='red')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(14,8))\n",
    "# plt.errorbar(y, pred, \n",
    "#              [pred-pred_lower, pred_upper-pred], fmt='o', alpha=0.1)\n",
    "# plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd4efb",
   "metadata": {},
   "source": [
    "### Bootstrapping and evaluating out of training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064445aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xgb'\n",
    "\n",
    "preds_bootstrap = {}\n",
    "preds_bootstrap_eval = {}\n",
    "\n",
    "dataset = Dataset(df_total.set_index(['CIS20CD', 'date']), model_variables[model_name], \n",
    "          'median_prob', input_offset=0.001)\n",
    "\n",
    "x_train, x_eval, y_train, _ = dataset.temporal_split(start_date_test = df_cis_interpolated.date.max()  + datetime.timedelta(1))\n",
    "y_train = y_train.dropna()\n",
    "x_train = x_train.loc[y_train.index]\n",
    "preds_bootstrap[model_name], preds_bootstrap_eval[model_name] = bootstrap(dict_models[model_name], \n",
    "                                                                          x_train, y_train, x_eval=x_eval, repeat=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "z = preds_bootstrap[model_name].mean(1).groupby('date').mean().rolling('7D').mean()\n",
    "zerror = (2*preds_bootstrap[model_name].std(1)/np.sqrt(n_preds)).groupby('date').apply(lambda x:np.sqrt((x**2).mean()))\n",
    "\n",
    "z_eval = preds_bootstrap_eval[model_name].mean(1).groupby('date').mean().rolling('7D').mean()\n",
    "z_eval_error = (2*preds_bootstrap_eval[model_name].std(1)/np.sqrt(repeat)).groupby('date').apply(lambda x:np.sqrt((x**2).mean()))\n",
    "\n",
    "\n",
    "plt.plot(y.groupby('date').mean().rolling('7D').mean(), color='black', label='data')\n",
    "plt.plot(z.index, z, color='blue', label=f'mean prediction ({model_labels[model_name]})')\n",
    "plt.errorbar(z.index, z, \n",
    "             zerror.rolling('7D').mean(),\n",
    "             color='blue', alpha=0.7, label='Boostrap 95% CI')\n",
    "\n",
    "# plt.plot(z_eval.index, z_eval, color='blue') #, label=f'mean prediction ({model_labels[model_name]})')\n",
    "# plt.errorbar(z_eval.index, z_eval, \n",
    "#              z_eval_error.rolling('7D').mean(),\n",
    "#              color='blue', alpha=0.7)\n",
    "\n",
    "plt.ylabel('CIS % infected (log10)', fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037879b8",
   "metadata": {},
   "source": [
    "## Data figures for article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99967b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Dataset(df.set_index(['CIS20CD', 'date']), all_variables, 'median_prob', input_offset=0.001).prepare_no_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = all_variables\n",
    "variables.remove('reac_vol_control')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(x[variables].corr(), cmap='coolwarm', vmin=-1.)\n",
    "locs, labels=plt.xticks()\n",
    "plt.xticks(range(len(x[variables].columns)), \n",
    "           [(variable_labels[l] if l in variable_labels else l) for l in x[variables].columns],\n",
    "           rotation=45, horizontalalignment='right', fontsize=12)\n",
    "plt.yticks(range(len(x[variables].columns)), \n",
    "           [(variable_labels[l] if l in variable_labels else l) for l in x[variables].columns],\n",
    "           horizontalalignment='right', fontsize=12)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel(f'Pearson Correlation', fontsize=15, rotation=270, labelpad=20)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1189033",
   "metadata": {},
   "source": [
    "#### PCA decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18579cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "variables = sample_variables\n",
    "\n",
    "pca = PCA(n_components=len(x[variables].columns))\n",
    "pca.fit(x[variables])\n",
    "plt.plot(range(1, len(variables)+1), np.cumsum(pca.explained_variance_ratio_)*100, '--o', markersize=8)\n",
    "plt.ylabel('explained variance (%)', fontsize=14)\n",
    "plt.xlabel('components', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some nationally averaged variables\n",
    "for col in ['sars_cov2_gc_l_mean', 'ammonia_mg_l', 'control_gc_l_mean', 'sample_ph_pre_ansis', \"sars_below_loq\", 'sars_below_lod', 'target_gene_N1']:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_ww.groupby('date').mean().rolling('7D').mean()[col], label=col)\n",
    "    plt.xlim(datetime.datetime(2020, 8, 15))\n",
    "#     plt.ylabel('SARS-CoV2 Concentration Log10(gc/L)', fontsize=13)\n",
    "    plt.ylabel('Log10', fontsize=14)\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wastewater)",
   "language": "python",
   "name": "wastewater"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
